{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ethanlmines/blue_dir/conda_envs/gatbert/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# STL\n",
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "# 3rd Party\n",
    "import torch\n",
    "import lightning as L\n",
    "torch.manual_seed(0)\n",
    "from transformers import BertModel, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Literal\n",
    "\n",
    "class BasisLinear(L.LightningModule):\n",
    "    def __init__(self,\n",
    "                 in_features: Tuple[int],\n",
    "                 out_features: int,\n",
    "                 n_bases: int,\n",
    "                 n_projections: Tuple[int]):\n",
    "        \"\"\"\n",
    "        Defines a collection of N linear transformations\n",
    "        that are all parameterized by a shared set of B basis matrices\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.__in_features = tuple(in_features)\n",
    "        self.__out_features = out_features\n",
    "        self.__n_bases = n_bases\n",
    "        self.__n_projections = n_projections\n",
    "\n",
    "        matched_dims = []\n",
    "        for (in_dim, proj_dim) in zip(reversed(self.__in_features[:-1]), reversed(self.__n_projections)):\n",
    "            if in_dim == proj_dim:\n",
    "                matched_dims.insert(0, proj_dim)\n",
    "        self.__matched_dims = matched_dims\n",
    "\n",
    "        # We could do one layer with stacked weight matrices, but that will also affect the fan-in values for the Xavier initializer...\n",
    "        self.__bases = [torch.nn.Linear(self.__in_features[-1], self.__out_features, bias=False) for _ in range(n_bases)]\n",
    "\n",
    "        # (O, num_bases)\n",
    "        coefficient_data = torch.empty(*self.__n_projections, self.__n_bases)\n",
    "        torch.nn.init.xavier_normal_(coefficient_data) # FIXME: Better initializer to use for this?\n",
    "        self.__coefficients = torch.nn.parameter.Parameter(coefficient_data)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            x:\n",
    "                Tensor of shape (..., in_features)\n",
    "\n",
    "        \n",
    "        Returns:\n",
    "            `torch.Tensor`:\n",
    "                Tensor of dimensions (..., n_projections, out_features)\n",
    "        \"\"\"\n",
    "        assert tuple(x.shape[-len(self.__in_features):]) == self.__in_features\n",
    "\n",
    "        # TODO: Could do this with a single linear layer--more efficient\n",
    "        # (*leading_x_dims, num_bases, out_features)\n",
    "        basis_vecs = torch.stack([basis(x) for basis in self.__bases], dim=-2)\n",
    "\n",
    "        basis_shape = (\n",
    "            *(x.shape[:-len(self.__matched_dims) - 1]),\n",
    "\n",
    "            # Broadcast over unmatched projection dims\n",
    "            *(1 for _ in self.__n_projections[:len(self.__n_projections) - len(self.__matched_dims)]),\n",
    "            *self.__matched_dims,\n",
    "            \n",
    "            self.__n_bases,\n",
    "            self.__out_features\n",
    "        )\n",
    "        basis_vecs = basis_vecs.view(*basis_shape)\n",
    "\n",
    "        coeff_shape = (\n",
    "            *(1 for _ in x.shape[:-len(self.__matched_dims) - 1]),\n",
    "\n",
    "            *self.__n_projections,\n",
    "\n",
    "            self.__n_bases,\n",
    "            1                # Broadcast over out_features\n",
    "        )\n",
    "        coeff_view = self.__coefficients.view(*coeff_shape)\n",
    "        multiplied = coeff_view * basis_vecs\n",
    "\n",
    "        \n",
    "        # (*leading_dims, *n_projections, out_features)\n",
    "        summed = torch.sum(multiplied, dim=-2)\n",
    "        return summed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_until(tensor: torch.Tensor, end_dim=-1):\n",
    "    orig_indices = tensor.indices()\n",
    "\n",
    "    if end_dim < 0:\n",
    "        end_dim = len(orig_indices) - end_dim\n",
    "    assert end_dim > 0\n",
    "\n",
    "    new_dim_size = tensor.shape[end_dim]\n",
    "    cum_indices = orig_indices[end_dim]\n",
    "    for dim in range(end_dim - 1, -1, -1):\n",
    "        cum_indices += orig_indices[dim] * new_dim_size\n",
    "        new_dim_size *= tensor.shape[dim]\n",
    "\n",
    "    new_indices = torch.concatenate([\n",
    "        cum_indices.unsqueeze(0),\n",
    "        orig_indices[end_dim + 1:]\n",
    "    ])\n",
    "    sparse_tense = torch.sparse_coo_tensor(\n",
    "        indices=new_indices,\n",
    "        values=tensor.values(),\n",
    "        size=(new_dim_size, *tensor.shape[end_dim + 1:])\n",
    "    )\n",
    "    return sparse_tense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RGATAttentionHead(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 attention_units: int,\n",
    "                 out_features: int,\n",
    "                 n_heads: int,\n",
    "                 n_relations: int,\n",
    "                 n_bases: int,\n",
    "                 attention_mode: Literal['argat', 'wirgat'] = 'wirgat'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features:\n",
    "                Number of input and output features\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert out_features % n_heads == 0\n",
    "        assert attention_mode in {'argat', 'wirgat'}\n",
    "\n",
    "        self.__in_features = in_features                          # F from RGAT\n",
    "        self.__attention_units = attention_units                  # D from RGAT\n",
    "        self.__chunked_features = out_features // n_heads         # F'/K \n",
    "\n",
    "        self.__n_bases = n_bases\n",
    "        self.__n_relations = n_relations\n",
    "        self.__n_heads = n_heads\n",
    "        self.__attention_mode = attention_mode\n",
    "\n",
    "\n",
    "        self.__projection = BasisLinear(\n",
    "            in_features=(self.__in_features,),\n",
    "            out_features=self.__chunked_features,\n",
    "            n_bases=self.__n_bases,\n",
    "            n_projections=[self.__n_relations, self.__n_heads]\n",
    "        )\n",
    "\n",
    "        # The query and key projections share the same bases\n",
    "        self.__qk_proj = BasisLinear(\n",
    "            in_features=(self.__n_relations, self.__n_heads, self.__chunked_features),\n",
    "            out_features=self.__attention_units * 2,\n",
    "            n_bases=self.__n_bases,\n",
    "            n_projections=[self.__n_relations, self.__n_heads]\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, node_states, edges):\n",
    "        \"\"\"\n",
    "\n",
    "        node_states: (batch, nodes, features)\n",
    "        edges: sparse boolean array (batch, nodes, nodes, relations)\n",
    "        \"\"\"\n",
    "        (batch_size, n_nodes) = node_states.shape[:-1]\n",
    "\n",
    "        # (batch, nodes, relations, heads, chunked_features)\n",
    "        V = self.__projection(node_states)\n",
    "\n",
    "        # (batch, nodes, relations, heads 2, attention_units)\n",
    "        QK = self.__qk_proj(V)\n",
    "        # (batch, nodes, relations, heads, attention_units)\n",
    "        Q, K = torch.split(QK, self.__attention_units, dim=-1)\n",
    "\n",
    "        edge_indices = edges.indices()\n",
    "\n",
    "        # (total_edges, num_heads, attention_units)\n",
    "        Q_prime = Q[edge_indices[0], edge_indices[1], edge_indices[3], :, :]\n",
    "        K_prime = K[edge_indices[0], edge_indices[2], edge_indices[3], :, :]\n",
    "        # (total_edges, num_heads)\n",
    "        logits = (Q_prime * K_prime).sum(dim=-1)\n",
    "\n",
    "        if self.__attention_mode == 'wirgat':\n",
    "            sparse_logits = torch.sparse_coo_tensor(\n",
    "                indices=edge_indices, values=logits,\n",
    "                size=(batch_size, n_nodes, n_nodes, self.__n_relations, self.__n_heads)\n",
    "            )\n",
    "            # Compute a separate probability distribution for each relation\n",
    "            sparse_attention = torch.sparse.softmax(sparse_logits, dim=-3)\n",
    "            # Validate probability distributions\n",
    "            # assert torch.all(torch.abs(torch.sum(sparse_attention.to_dense(), -3) - 1) < 1e6)\n",
    "        else:\n",
    "            mask_indices = torch.stack([\n",
    "                edge_indices[0],\n",
    "                edge_indices[1],\n",
    "                edge_indices[2] * self.__n_relations + edge_indices[3],\n",
    "            ], dim=0)\n",
    "            sparse_logits = torch.sparse_coo_tensor(\n",
    "                indices=mask_indices, values=logits,\n",
    "                size=(batch_size, n_nodes, n_nodes * self.__n_relations, self.__n_heads),\n",
    "                requires_grad=True\n",
    "            )\n",
    "            sparse_attention = torch.sparse.softmax(sparse_logits, dim=-2)\n",
    "            # Validate probability distributions\n",
    "            # assert torch.all(torch.abs(torch.sum(sparse_attention.to_dense(), -2) - 1) < 1e6)\n",
    "        edge_attentions = sparse_attention.values()\n",
    "        \n",
    "\n",
    "        # (batch, dest_nodes, relations, heads, chunk) --> (edges, heads, chunks)\n",
    "        V_prime = V[edge_indices[0], edge_indices[2], edge_indices[3]]\n",
    "        # (edges, heads, chunks)\n",
    "        elwise_prod = torch.unsqueeze(edge_attentions, -1) * V_prime\n",
    "        # (edges, out_features)\n",
    "        elwise_prod = torch.flatten(elwise_prod, start_dim=1)\n",
    "\n",
    "        # (batch_size*source_nodes, edges)\n",
    "        edge_mask = torch.sparse_coo_tensor(\n",
    "            indices=torch.stack([edge_indices[0]*n_nodes + edge_indices[1], torch.arange(edge_indices.shape[1])]),\n",
    "            values=torch.ones(edge_indices.shape[1]),\n",
    "            size=(batch_size * n_nodes, edge_indices.shape[1]),\n",
    "            check_invariants=True\n",
    "        )\n",
    "\n",
    "        # (batch_size * source_nodes, out_features)\n",
    "        flat_node_states = torch.sparse.mm(edge_mask, elwise_prod)\n",
    "\n",
    "        # (batch_size, source_nodes, out_features)\n",
    "        node_states = flat_node_states.view(batch_size, n_nodes, -1)\n",
    "        return node_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "model = RGATAttentionHead(in_features=in_features,\n",
    "                          attention_units=attention_units,\n",
    "                          out_features=out_features,\n",
    "                          n_heads=n_heads,\n",
    "                          n_relations=n_relations,\n",
    "                          n_bases=n_bases,\n",
    "                          attention_mode='argat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 264])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(random_features, random_adj)\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits grad: tensor([[-1.0378e+00, -6.7509e-01, -2.8978e-01, -6.1378e-01, -2.2774e-01,\n",
      "          2.9163e-01],\n",
      "        [-1.7269e+00,  6.4099e-02, -1.3452e+00, -1.7433e-01, -2.3266e+00,\n",
      "         -5.7234e-01],\n",
      "        [ 3.0749e+00, -2.2655e+00,  2.4762e-01, -1.6088e+00, -9.8352e-01,\n",
      "         -1.7201e-01],\n",
      "        ...,\n",
      "        [ 6.3667e-01,  6.4911e-01,  7.7401e-04, -3.0992e-01,  1.5062e-01,\n",
      "         -8.9753e-01],\n",
      "        [ 2.5477e-01,  6.1890e-01,  1.5265e-01,  8.2389e-02, -5.5311e-01,\n",
      "          1.5517e-01],\n",
      "        [-1.2211e-01,  2.1029e-01, -1.0515e-02,  2.1513e-02, -3.0218e-01,\n",
      "         -4.7483e-01]])\n"
     ]
    }
   ],
   "source": [
    "loss = torch.sum(output)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 123\n",
    "attention_units = 53\n",
    "out_features = 264\n",
    "n_heads = 6\n",
    "n_relations = 7\n",
    "n_bases = 3\n",
    "max_nodes = 10\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 123])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = torch.Generator().manual_seed(1)\n",
    "random_features = 5 * (torch.randn(batch_size, max_nodes, in_features, generator=gen) - .5)\n",
    "random_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 0, 0,  ..., 4, 4, 4],\n",
       "                       [0, 0, 0,  ..., 9, 9, 9],\n",
       "                       [0, 0, 0,  ..., 9, 9, 9],\n",
       "                       [1, 2, 5,  ..., 3, 4, 6]]),\n",
       "       values=tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
       "       size=(5, 10, 10, 7), nnz=1779, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = torch.Generator().manual_seed(2)\n",
    "random_adj = torch.randint(0, 2, size=[batch_size, max_nodes, max_nodes, n_relations], generator=gen).to_sparse()\n",
    "random_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gatbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

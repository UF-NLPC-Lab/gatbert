{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5903c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stance_gator.data_modules import StanceCorpus, StanceDataModule\n",
    "from stance_gator.span_module import SpanModule\n",
    "from stance_gator.torch_utils import load_module\n",
    "from stance_gator.constants import TriStance\n",
    "from lightning.fabric.utilities.apply_func import move_data_to_device\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0e63c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76ec3791",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type bert_for_stance. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertForStance were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.1.bias', 'classifier.1.weight', 'classifier.3.bias', 'classifier.3.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# ckpt_path = '/home/ethanlmines/blue_dir/experiments/lightning_logs/30MayNesyStance/checkpoints/epoch=03-val_macro_f1=0.761.ckpt'\n",
    "# ckpt_path = '/home/ethanlmines/blue_dir/experiments/lightning_logs/31MayQuarterTemp/checkpoints/epoch=03-val_macro_f1=0.757.ckpt'\n",
    "# ckpt_path = '/home/ethanlmines/blue_dir/experiments/lightning_logs/31MayQuarterTemp/checkpoints/epoch=03-val_macro_f1=0.757.ckpt'\n",
    "# checkpoint_dir = \"/home/ethanlmines/blue_dir/experiments/lightning_logs/2JunSpanMod_Des25/checkpoints/\"\n",
    "checkpoint_dir = \"/home/ethanlmines/blue_dir/experiments/lightning_logs/2JunSpanMod_Des50/checkpoints/\"\n",
    "ckpt_path = glob.glob(os.path.join(checkpoint_dir, \"*.ckpt\"))[0]\n",
    "span_mod: SpanModule  = load_module(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8922213f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing /home/ethanlmines/blue_dir/datasets/VAST/vast_zero_dev.csv: 0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing /home/ethanlmines/blue_dir/datasets/VAST/vast_zero_dev.csv: 1019it [00:03, 332.25it/s]\n",
      "/home/ethanlmines/blue_dir/conda_envs/stance_gator_dev/lib/python3.12/site-packages/torch/utils/data/dataset.py:473: UserWarning: Length of split at index 0 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(\n",
      "/home/ethanlmines/blue_dir/conda_envs/stance_gator_dev/lib/python3.12/site-packages/torch/utils/data/dataset.py:473: UserWarning: Length of split at index 1 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_mod = StanceDataModule(\n",
    "    [StanceCorpus(\n",
    "        path=\"/home/ethanlmines/blue_dir/datasets/VAST/vast_zero_dev.csv\",\n",
    "        corpus_type='vast',\n",
    "        data_ratio=(0, 0, 1)\n",
    "    )]\n",
    ")\n",
    "data_mod.encoder = span_mod.encoder\n",
    "data_mod.setup('predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0656ea87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p> <strong>Target</strong>: online learning </p><p> <strong>Sample</strong>: i would think it would depend on the individual student. my son and my grandson have both taken courses on - line and have done very well!! perhaps as there are less distractions, working at <mark>their own pace and on a time when they are more receptive to learning. they might miss the interaction physically.. but... the plus out</mark> ##weighs the minisus. and they are not involved with less studious students who cause many distractions. </p><p> <strong>Ground Truth</strong>: favor </p><p> <strong>Prediction from whole doc</strong>: ['P(neutral)', 'P(against)', 'P(favor)'] = ['0.000', '0.007', '0.992'] </p><p> <strong>Prediction from highlighted span</strong>: ['P(neutral)', 'P(against)', 'P(favor)'] = ['0.004', '0.001', '0.995'] </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p> <strong>Target</strong>: culture division </p><p> <strong>Sample</strong>: as an american latino i do not at all like the separation between &#x27; us &#x27; and everyone else. we are one nation. why are we so quick to say latino families should be afforded higher education? how, in <mark>this age of political correctness, is that okay? are we going to run around wearing brown pride shirts next? if white folk decided to have &#x27; white only &#x27; forums or &#x27; white only &#x27; college programs that would be</mark> labeled racist and exclusionary. we latinos separate ourselves enough by insisting on very little to zero assimilation in our communities and on being latin in everything we say, do, read and watch. we even teach our children to shun away from saying they are americans like its a bad thing. college is not a right. as such, we shouldn &#x27; t to get a free ride just because we happen to speak spanish at home. it &#x27; s an archaic way of thinking and not what the american dream is supposed to be. i do not support segregation in any form. it creates animosity and we have enough of that already. i don &#x27; t agree with the all black institutions or the nedro college fund either. </p><p> <strong>Ground Truth</strong>: against </p><p> <strong>Prediction from whole doc</strong>: ['P(neutral)', 'P(against)', 'P(favor)'] = ['0.000', '0.002', '0.997'] </p><p> <strong>Prediction from highlighted span</strong>: ['P(neutral)', 'P(against)', 'P(favor)'] = ['0.045', '0.001', '0.954'] </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p> <strong>Target</strong>: queen elizabeth ii </p><p> <strong>Sample</strong>: simply said the queen is not going to step down. upon ascending to the throne she made a vow to serve her people until her death. words and the people who <mark>spoke them truly meant something at that time and still do to people of her generation. queen elizabeth came to the throne during a very difficult period for her people and the world and she helped lead her nation from those days to today always as a constant source of pride and inspiration.</mark> and it appears that the qualities that made her a loved and inspirational leader skipped a generation bypassing her son, charles, and now appears rooted in her grandson, william. so i say save the questions about stepping down for charles for the day after he ascends to the throne. </p><p> <strong>Ground Truth</strong>: favor </p><p> <strong>Prediction from whole doc</strong>: ['P(neutral)', 'P(against)', 'P(favor)'] = ['0.001', '0.000', '0.999'] </p><p> <strong>Prediction from highlighted span</strong>: ['P(neutral)', 'P(against)', 'P(favor)'] = ['0.001', '0.000', '0.999'] </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p> <strong>Target</strong>: austerity </p><p> <strong>Sample</strong>: this lack of pay is not limited to high school or college internships. it is found throughout the business world. people are encouraged to blog for a major media organization not <mark>for pay, but for &quot; the exposure, &quot; only to see that media organization sold to another company for hundreds of millions of dollars. workers age 50 and over, who still have much to contribute, are thrown out of jobs in a subtle form of</mark> age discrimination and are then expected to work for free as part of their &quot; retraining &quot; to ease into a new profession that might pay thousands less in the end. another poster on here mentioned volunteer workers who put in long hours while the heads of those charities reap huge salaries and benefits. the trend toward free labor is another indication of our moral decline. we have to take a stand. people, when you get up tomorrow morning and look at yourself in the mirror, repeat these words : &quot; i will not work for free. &quot; </p><p> <strong>Ground Truth</strong>: neutral </p><p> <strong>Prediction from whole doc</strong>: ['P(neutral)', 'P(against)', 'P(favor)'] = ['0.001', '0.997', '0.002'] </p><p> <strong>Prediction from highlighted span</strong>: ['P(neutral)', 'P(against)', 'P(favor)'] = ['0.009', '0.991', '0.000'] </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p> <strong>Target</strong>: social disorder </p><p> <strong>Sample</strong>: comments are a useful and frequently informative part of online news ; they should be encouraged but much more closely monitored. for openers, commenters should be allowed only one comment per article to avoid these ubiquitous back and forth, <mark>witless arguments which often clog the comments section. obscene, vulgar and personal attacks should be edited out, but care must be exercised. many subjects almost demand strong comments</mark> which some may find offensive, but do not really cross the line. some are clearly at the far left, right, or some other extreme, but often bring out ignored, but important points of view. in addition, many articles and editorials contain claims that are either wrong or at best distorted, despite usually high standards of editorial review. comments are essential for correcting these problems. some blogs, like prof juan cole usually contain thoughtful, informed and useful information. others seem to call forth the the worst forms of trolls, bullys, idiots and haters. proper monitoring, i believe can correct the abuses and allow a very important part of the internet to thrive. </p><p> <strong>Ground Truth</strong>: neutral </p><p> <strong>Prediction from whole doc</strong>: ['P(neutral)', 'P(against)', 'P(favor)'] = ['0.000', '0.995', '0.004'] </p><p> <strong>Prediction from highlighted span</strong>: ['P(neutral)', 'P(against)', 'P(favor)'] = ['0.000', '0.951', '0.048'] </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p> <strong>Target</strong>: nonmuslim </p><p> <strong>Sample</strong>: i too prefer to dress modestly. but a person who is not muslim and does not appear superficially to be muslim who chooses to wear a headscarf is not at all in the <mark>same position or even temporarily living the experience of one who is muslim and forced to do so.</mark> i don &#x27; t see how wearing a headscarf as a non - muslim does anything to improve the lives of muslim women. </p><p> <strong>Ground Truth</strong>: against </p><p> <strong>Prediction from whole doc</strong>: ['P(neutral)', 'P(against)', 'P(favor)'] = ['0.001', '0.005', '0.994'] </p><p> <strong>Prediction from highlighted span</strong>: ['P(neutral)', 'P(against)', 'P(favor)'] = ['0.110', '0.115', '0.775'] </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p> <strong>Target</strong>: woman ' s right </p><p> <strong>Sample</strong>: the international monetary fund, the european commission and the european central banks have been acting like extortionist racketeers! if i were the head of state of one <mark>of the other euro - zone countries, i would initiate procedures to leave the euro - zone immediately, based on the morally depraved way they have bullied greece into financial ruin. most of the &quot; money &quot; used to create those so - called &quot; loans &quot; was &quot; created out of thin air &quot; to begin with</mark> , so the co - called &quot; lenders &quot; of those loans will lose nothing if greece &quot; defaults &quot; on those &quot; loans &quot;. </p><p> <strong>Ground Truth</strong>: neutral </p><p> <strong>Prediction from whole doc</strong>: ['P(neutral)', 'P(against)', 'P(favor)'] = ['0.999', '0.000', '0.000'] </p><p> <strong>Prediction from highlighted span</strong>: ['P(neutral)', 'P(against)', 'P(favor)'] = ['0.999', '0.001', '0.000'] </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p> <strong>Target</strong>: publish </p><p> <strong>Sample</strong>: some other sites or newspapers may allow vulgarity and animosity but i have never seen it on nyt, and in fact i feel the comments make <mark>the article more interesting and sparks discussion. i look forward to reading others &#x27; thoughts on the subjects explored by the authors of the articles published here. on other sites, i rarely read the comments. i do appreciate the moderation very much</mark> . i hope nyt does not do away with comments. </p><p> <strong>Ground Truth</strong>: neutral </p><p> <strong>Prediction from whole doc</strong>: ['P(neutral)', 'P(against)', 'P(favor)'] = ['0.000', '0.001', '0.999'] </p><p> <strong>Prediction from highlighted span</strong>: ['P(neutral)', 'P(against)', 'P(favor)'] = ['0.000', '0.000', '1.000'] </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "span_mod.eval().to('cuda')\n",
    "tokenizer = span_mod.encoder.tokenizer\n",
    "i = 0\n",
    "\n",
    "def toks_to_html_str(toks):\n",
    "    return html.escape(tokenizer.convert_tokens_to_string(toks))\n",
    "\n",
    "class_prob_prefix = str([f\"P({s.name})\" for s in TriStance])\n",
    "\n",
    "special_ids = set(tokenizer.all_special_ids)\n",
    "for batch in data_mod.test_dataloader():\n",
    "    batch = move_data_to_device(batch, span_mod.device)\n",
    "    labels = batch.pop('labels')\n",
    "    output: SpanModule.Output = span_mod(**batch)\n",
    "\n",
    "\n",
    "    iterator = zip(\n",
    "                    labels.detach().cpu().tolist(),\n",
    "                    batch['input_ids'].detach().tolist(),\n",
    "                    output.start_inds.detach().cpu().tolist(),\n",
    "                    output.stop_inds.detach().cpu().tolist(),\n",
    "                    output.first_pass.logits.detach().cpu().numpy(),\n",
    "                    output.second_pass.logits.detach().cpu().numpy(),\n",
    "    )\n",
    "    for label_id, id_list, start_index, stop_index, first_logits, second_logits in iterator:\n",
    "\n",
    "        context_ids = []\n",
    "        target_ids = []\n",
    "        span_start = None\n",
    "        span_end = None\n",
    "        i = 0\n",
    "        while i < len(id_list) and id_list[i] in special_ids:\n",
    "            i += 1\n",
    "        while i < len(id_list) and id_list[i] not in special_ids:\n",
    "            if i == start_index:\n",
    "                span_start = i\n",
    "            if i == stop_index:\n",
    "                span_end = i\n",
    "            context_ids.append(int(id_list[i]))\n",
    "            i += 1\n",
    "        while i < len(id_list) and id_list[i] in special_ids:\n",
    "            i += 1\n",
    "        while i < len(id_list) and id_list[i] not in special_ids:\n",
    "            target_ids.append(int(id_list[i]))\n",
    "            i += 1\n",
    "        assert span_start is not None and span_end is not None\n",
    "\n",
    "        html_toks = []\n",
    "\n",
    "        target_str = tokenizer.decode(target_ids)\n",
    "        context_toks = tokenizer.convert_ids_to_tokens(context_ids)\n",
    "\n",
    "        pre_span  = toks_to_html_str(context_toks[:span_start])\n",
    "        span      = toks_to_html_str(context_toks[span_start:span_end + 1])\n",
    "        post_span = toks_to_html_str(context_toks[span_end + 1:])\n",
    "\n",
    "        html_toks.append(f'<p> <strong>Target</strong>: {target_str} </p>')\n",
    "        html_toks.append(f'<p> <strong>Sample</strong>: {pre_span} <mark>{span}</mark> {post_span} </p>')\n",
    "\n",
    "\n",
    "        format_numlist = lambda x: [f\"{round(v, 3):.3f}\" for v in x]\n",
    "\n",
    "        html_toks.append(f'<p> <strong>Ground Truth</strong>: {TriStance(label_id).name} </p>')\n",
    "        html_toks.append(f'<p> <strong>Prediction from whole doc</strong>: {class_prob_prefix} = {format_numlist(softmax(first_logits))} </p>')\n",
    "        html_toks.append(f'<p> <strong>Prediction from highlighted span</strong>: {class_prob_prefix} = {format_numlist(softmax(second_logits))} </p>')\n",
    "\n",
    "        html_str = \"\".join(html_toks)\n",
    "        display(HTML(html_str))\n",
    "        exit = input(\"Press enter to continue (q to quit)\").lower() == 'q'\n",
    "        if exit:\n",
    "            break\n",
    "    if exit:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327f56d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'token_type_ids', 'context_mask'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff83698c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p> <strong>Target</strong>: female modesty </p><p> <strong>Document</strong>: the only solidarity the hijab shows is with that most ancient of patriarchal male control strategies, shifting the burden of morality, family and male honor, etc., onto the shoulders of female modesty. it is no different from orthodox jewish married women having to cover their hair, or the in the middle ages married women in europe were expected to wear a coif to cover their hair, and is nakedly an attempt to confine women &#x27; s sexual nature in as small a space as possible. it stands in relationship to footbinding and to female genital mutilation, albeit at another point on the bellcurve of control of women and control of female sexuality. if you insist on sacrificing yourself on this altar to show ethnic solidarity, don &#x27; t be surprised when people conclude that islam is still stuck in the past. as rhett butler once famously said to scarlett in &quot; gone with the wind &quot; when she refused to abandon black mourning clothes for a husband she not only didn &#x27; t love, but despised, &quot; how closely women clutch the chains that bind them! &quot; find another way to announce your religious / ethnic identity. your daughters deserve a better message. </p><p> <strong>Prediction</strong>: P(favor) = 0.6407448053359985 </p><table><thead> <tr> <th>Token</th> <th>Att</th> <th>Sent</th> <th>Contribution</th> </tr> </thead><tbody><tr> <td>modest</td> <td>0.07361588627099991</td> <td>0.7244386076927185</td> <td>0.0533301904797554</td> </tr><tr> <td>female</td> <td>0.045711301267147064</td> <td>0.7637415528297424</td> <td>0.0349116213619709</td> </tr><tr> <td>##ital</td> <td>0.04429059103131294</td> <td>0.7480758428573608</td> <td>0.03313272073864937</td> </tr><tr> <td>male</td> <td>0.04917573928833008</td> <td>0.5769947171211243</td> <td>0.028374141082167625</td> </tr><tr> <td>sexual</td> <td>0.03629869967699051</td> <td>0.734909176826477</td> <td>0.026676246896386147</td> </tr><tr> <td>sexuality</td> <td>0.034179843962192535</td> <td>0.7561362385749817</td> <td>0.025844618678092957</td> </tr><tr> <td>women</td> <td>0.03435264900326729</td> <td>0.7336478233337402</td> <td>0.02520274557173252</td> </tr><tr> <td>women</td> <td>0.02912239544093609</td> <td>0.6735926866531372</td> <td>0.019616631790995598</td> </tr><tr> <td>family</td> <td>0.03144524246454239</td> <td>0.5897860527038574</td> <td>0.01854596473276615</td> </tr><tr> <td>male</td> <td>0.034589290618896484</td> <td>0.5014801621437073</td> <td>0.017345843836665154</td> </tr></tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# html_str = '<table><tbody> <tr> <td colspan=\"2\">Doof</td> </tr> <tr> <td>Hi</td> <td>Yo</td> <td>Wassup</td> </tbody></table>'\n",
    "display(HTML(html_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23a1849b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0532864"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0736 * 0.724"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385a7536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stance_gator_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
